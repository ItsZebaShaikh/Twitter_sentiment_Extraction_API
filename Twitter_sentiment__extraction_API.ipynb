{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_sentiment _extraction_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1p95X0CqpMs2PIfArdtPb5FPG3qBfu-bj",
      "authorship_tag": "ABX9TyOzKU9SPSiWYv1i4Lqif9AM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItsZebaShaikh/Twitter_sentiment_Extraction_API/blob/main/Twitter_sentiment__extraction_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q350AcEmFuIm"
      },
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "####input your credentials here\n",
        "consumer_key = 'xxxxxxxxxxxxxxxxxxxxxxx'\n",
        "consumer_secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "access_token = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "access_token_secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb-PrVMvF8Mu"
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "\n",
        "query='WorldNatureConservationDay'\n",
        "max_tweets=4000\n",
        "searched_tweets= [status for status in tweepy.Cursor (api.search,q=query).items(max_tweets)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbB_2SPhF8bU"
      },
      "source": [
        "import re\n",
        "def remove_url(txt):\n",
        "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\",txt).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldcabD8wNW-n"
      },
      "source": [
        "tweets_no_urls = [remove_url(tweet.text) for tweet in searched_tweets]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcrckqccN8Oy"
      },
      "source": [
        "from textblob import TextBlob\n",
        "sentiment_obj = [TextBlob(tweet) for tweet in tweets_no_urls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4qFYmFCOWhH"
      },
      "source": [
        "sentimet_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_obj]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kdRQxTbQiHp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "ad58133a-892c-4d60-d344-a488f060e060"
      },
      "source": [
        "sentiment_df = pd.DataFrame(sentimet_values, columns=['Polarity','Tweet'])\n",
        "\n",
        "sentiment_df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT RoyalFamily In 2016 The Queen hosted a show...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT RoyalFamily On WorldNatureConservationDay w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>RT rldaindia On World Nature Conservation Day ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>RT FidcIndia On this WorldNatureConservationDa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT KanihaAreaMCL Lets take an oath on this Wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>RT PypAyurved Protect nature today for a bette...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCity The year is 2045 Phil Foden is our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.850000</td>\n",
              "      <td>RT RowdyPriyaDhfm3 ThisIsDSP MythriOfficial MP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.395238</td>\n",
              "      <td>RT SadhguruJV Right now the most important asp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT puniatanuj WorldNatureConservationDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT puniatanuj plpunia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Polarity                                              Tweet\n",
              "0   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...\n",
              "1  -0.200000  RT urstrulyMahesh Save water recycle manage wa...\n",
              "2  -0.200000  RT urstrulyMahesh Save water recycle manage wa...\n",
              "3  -0.200000  RT urstrulyMahesh Save water recycle manage wa...\n",
              "4   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...\n",
              "5   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...\n",
              "6   0.000000  RT RoyalFamily In 2016 The Queen hosted a show...\n",
              "7   0.000000  RT RoyalFamily On WorldNatureConservationDay w...\n",
              "8   0.100000  RT rldaindia On World Nature Conservation Day ...\n",
              "9   0.500000  RT FidcIndia On this WorldNatureConservationDa...\n",
              "10  0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...\n",
              "11  0.000000  RT KanihaAreaMCL Lets take an oath on this Wor...\n",
              "12 -0.200000  RT urstrulyMahesh Save water recycle manage wa...\n",
              "13  0.500000  RT PypAyurved Protect nature today for a bette...\n",
              "14  0.000000  RT ManCity The year is 2045 Phil Foden is our ...\n",
              "15  0.850000  RT RowdyPriyaDhfm3 ThisIsDSP MythriOfficial MP...\n",
              "16 -0.200000  RT urstrulyMahesh Save water recycle manage wa...\n",
              "17  0.395238  RT SadhguruJV Right now the most important asp...\n",
              "18  0.000000           RT puniatanuj WorldNatureConservationDay\n",
              "19  0.000000                              RT puniatanuj plpunia"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzXXX75dQ5Pe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df6964af-197f-4738-86c3-0989e05f81f4"
      },
      "source": [
        "sentiment_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fproHh8RmN9"
      },
      "source": [
        "def f(sentiment_df):\n",
        "  if sentiment_df['Polarity']== 0.0:\n",
        "    val = 'Neutral'\n",
        "  elif sentiment_df['Polarity'] > 0:\n",
        "    val = 'Positive'\n",
        "  else:\n",
        "    val = 'Negative'\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkx8-AgpRxmr"
      },
      "source": [
        "sentiment_df['Sentiment'] = sentiment_df.apply(f,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7P1qsRmR-2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "9193091e-8578-4347-a4d9-3536317ae73f"
      },
      "source": [
        "sentiment_df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT RoyalFamily In 2016 The Queen hosted a show...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT RoyalFamily On WorldNatureConservationDay w...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>RT rldaindia On World Nature Conservation Day ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>RT FidcIndia On this WorldNatureConservationDa...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT KanihaAreaMCL Lets take an oath on this Wor...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>RT PypAyurved Protect nature today for a bette...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT ManCity The year is 2045 Phil Foden is our ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.850000</td>\n",
              "      <td>RT RowdyPriyaDhfm3 ThisIsDSP MythriOfficial MP...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.200000</td>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.395238</td>\n",
              "      <td>RT SadhguruJV Right now the most important asp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT puniatanuj WorldNatureConservationDay</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RT puniatanuj plpunia</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Polarity                                              Tweet Sentiment\n",
              "0   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral\n",
              "1  -0.200000  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "2  -0.200000  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "3  -0.200000  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "4   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral\n",
              "5   0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral\n",
              "6   0.000000  RT RoyalFamily In 2016 The Queen hosted a show...   Neutral\n",
              "7   0.000000  RT RoyalFamily On WorldNatureConservationDay w...   Neutral\n",
              "8   0.100000  RT rldaindia On World Nature Conservation Day ...  Positive\n",
              "9   0.500000  RT FidcIndia On this WorldNatureConservationDa...  Positive\n",
              "10  0.000000  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral\n",
              "11  0.000000  RT KanihaAreaMCL Lets take an oath on this Wor...   Neutral\n",
              "12 -0.200000  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "13  0.500000  RT PypAyurved Protect nature today for a bette...  Positive\n",
              "14  0.000000  RT ManCity The year is 2045 Phil Foden is our ...   Neutral\n",
              "15  0.850000  RT RowdyPriyaDhfm3 ThisIsDSP MythriOfficial MP...  Positive\n",
              "16 -0.200000  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "17  0.395238  RT SadhguruJV Right now the most important asp...  Positive\n",
              "18  0.000000           RT puniatanuj WorldNatureConservationDay   Neutral\n",
              "19  0.000000                              RT puniatanuj plpunia   Neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Q-7BHmSLrD"
      },
      "source": [
        "# we dont need the first column i.e. 'Polarity' column so we will drop it.\n",
        "sentiment_df.drop([\"Polarity\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWmSmvoK0KkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c6086fa9-ac9a-46b8-f058-2f537af00fbe"
      },
      "source": [
        "sentiment_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Sentiment\n",
              "0  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral\n",
              "1  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "2  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "3  RT urstrulyMahesh Save water recycle manage wa...  Negative\n",
              "4  RT ManCityPT O ano 2045 Phil Foden o treinador...   Neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocqw6y1GFMl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6739d44f-96ca-4760-b8c8-29edb05f6264"
      },
      "source": [
        "sentiment_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet        0\n",
              "Sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewojPwj40Olv"
      },
      "source": [
        "sentiment_df.to_csv('/content/drive/My Drive/API_WorldNatureConservationDay.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-8u-RCe58ZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6537431b-3832-40dd-bf63-698ad255f543"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "from zipfile import ZipFile\n",
        "filename = \"/content/drive/My Drive/597869_1074900_compressed_pretrained-roberta-base.h5.zip\"\n",
        "\n",
        "with ZipFile(filename,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4tvtCTW2E75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "fe425801-13f4-4a72-927e-bb3a12891b0f"
      },
      "source": [
        "# Load Libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import random\n",
        "from spacy.util import compounding\n",
        "from spacy.util import minibatch\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "# sklearn \n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "#nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "stop=set(stopwords.words('english'))\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from PIL import Image\n",
        "\n",
        "#Avoid warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!pip install transformers\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "\n",
        "from datetime import datetime as dt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=18e24c94d43392119d9d46fad98a6febda07e761dde271be7ff6b8a6f07bb966\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkTa_PFg2y8j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "90843ced-7b54-4851-aa1b-6775d37dad5f"
      },
      "source": [
        "#Reading the Datasets\n",
        "train = pd.read_csv(\"/content/drive/My Drive/train.csv\")\n",
        "test = pd.read_csv('/content/drive/My Drive/API_WorldNatureConservationDay.csv').fillna(\"\")\n",
        "test['Sentiment'] = test['Sentiment'].str.lower()\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage wa...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Sentiment\n",
              "0  RT ManCityPT O ano 2045 Phil Foden o treinador...   neutral\n",
              "1  RT urstrulyMahesh Save water recycle manage wa...  negative\n",
              "2  RT urstrulyMahesh Save water recycle manage wa...  negative\n",
              "3  RT urstrulyMahesh Save water recycle manage wa...  negative\n",
              "4  RT ManCityPT O ano 2045 Phil Foden o treinador...   neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUM90o5H4svJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4644787b-1736-4c6b-c551-96d724dadd7e"
      },
      "source": [
        "# Model Max length \n",
        "MAX_LEN = 96\n",
        "\n",
        "# Load Pretrained model of roberta\n",
        "PATH = '/content/drive/My Drive/'\n",
        "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file=PATH+'datasets_597869_1074900_vocab-roberta-base.json', \n",
        "    merges_file=PATH+'datasets_597869_1074900_merges-roberta-base.txt', \n",
        "    lowercase=True,\n",
        "    add_prefix_space=True\n",
        ")\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "PAD_ID = 1\n",
        "SEED = 88888\n",
        "LABEL_SMOOTHING = 0.1\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Sentiment ID value is encoded from tokenizer\n",
        "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... sentiment\n",
              "0  cb774db0d1  ...   neutral\n",
              "1  549e992a42  ...  negative\n",
              "2  088c60f138  ...  negative\n",
              "3  9642c003ef  ...  negative\n",
              "4  358bd9e861  ...  negative\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNg7fpVz5dwa"
      },
      "source": [
        "#cast to string data type\n",
        "train['text'] = train['text'].astype('str')\n",
        "train['selected_text'] = train['selected_text'].astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTlLj2t9X-K"
      },
      "source": [
        "#convert the training data into arrays that RoBERTa Algorithm understands.\n",
        "ct = train.shape[0] #27481\n",
        "\n",
        "# Initialising training inputs\n",
        "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "# Array with value 1 of shape(27481,96)\n",
        "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# Array with value 0 of shape(27481,96)\n",
        "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# Array with value 0 of shape(27481,96)\n",
        "start_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# Array with value 0 of shape(27481,96)\n",
        "end_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# Array with value 0 of shape(27481,96)\n",
        "\n",
        "for k in range(train.shape[0]):\n",
        "    \n",
        "    # FIND OVERLAP\n",
        "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
        "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
        "    \n",
        "    idx = text1.find(text2) # idx - position where the selected text are placed.\n",
        "    \n",
        "    # all character position as 0 and then places 1 for selected text position\n",
        "    chars = np.zeros((len(text1)))\n",
        "    chars[idx:idx+len(text2)]=1\n",
        "    # example [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
        "    if text1[idx-1]==' ': chars[idx-1] = 1 \n",
        "    enc = tokenizer.encode(text1) #  above example will become this -> [127, 3504, 16, 11902, 162] after tokenization i.e tokens\n",
        "        \n",
        "    # ID_OFFSETS -start and end index of text\n",
        "    offsets = []; idx=0\n",
        "    for t in enc.ids:\n",
        "        w = tokenizer.decode([t])\n",
        "        offsets.append((idx,idx+len(w))) #  [(0, 3), (3, 8), (8, 11), (11, 20), (20, 23)]\n",
        "        idx += len(w)\n",
        "    # START END TOKENS\n",
        "    toks = []\n",
        "    for i,(a,b) in enumerate(offsets):\n",
        "        sm = np.sum(chars[a:b]) # number of characters in selected text - [0.0,0.0,0.0,9.0,3.0] - bullying me\n",
        "        if sm>0: toks.append(i) # token position - selected text - [3, 4]\n",
        "        \n",
        "    s_tok = sentiment_id[train.loc[k,'sentiment']] # Encoded values by tokenizer\n",
        "    #Formating input for roberta model\n",
        "    input_ids[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n",
        "    attention_mask[k,:len(enc.ids)+3] = 1\n",
        "    if len(toks)>0:\n",
        "        start_tokens[k,toks[0]+2] = 1\n",
        "        end_tokens[k,toks[-1]+2] = 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqQMOvDK9e9Y"
      },
      "source": [
        "#Tokenizing the Test Data in the Same way we tokenized the train data\n",
        "\n",
        "ct = test.shape[0]\n",
        "# Initialize inputs\n",
        "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "# array with value 1 for shape (3534, 96)\n",
        "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# array with value 0 for shape (3534, 96)\n",
        "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "# array with value 0 for shape (3534, 96)\n",
        "for k in range(test.shape[0]):\n",
        "        \n",
        "    # INPUT_IDS\n",
        "    text1 = \" \"+\" \".join(test.loc[k,'Tweet'].split())\n",
        "    enc = tokenizer.encode(text1)                \n",
        "    s_tok = sentiment_id[test.loc[k,'Sentiment']]\n",
        "    #setting up of input ids - same as we did for train\n",
        "    input_ids_t[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n",
        "    attention_mask_t[k,:len(enc.ids)+3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JclA1-LM9mXy"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_weights(model, dst_fn):\n",
        "    weights = model.get_weights()\n",
        "    with open(dst_fn, 'wb') as f:\n",
        "        pickle.dump(weights, f)\n",
        "\n",
        "\n",
        "def load_weights(model, weight_fn):\n",
        "    with open(weight_fn, 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    model.set_weights(weights)\n",
        "    return model\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    # adjust the targets for sequence bucketing\n",
        "    ll = tf.shape(y_pred)[1]\n",
        "    y_true = y_true[:, :ll]\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred,\n",
        "        from_logits=False, label_smoothing=LABEL_SMOOTHING)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtIgGfJQFUxS"
      },
      "source": [
        "def build_model():\n",
        "    # Initialize keras layers\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n",
        "\n",
        "    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n",
        "    max_len = tf.reduce_max(lens)\n",
        "    ids_ = ids[:, :max_len]\n",
        "    att_ = att[:, :max_len]\n",
        "    tok_ = tok[:, :max_len]\n",
        "\n",
        "    # Fetching pretrained models      \n",
        "    config = RobertaConfig.from_pretrained(PATH+'datasets_597869_1074900_config-roberta-base.json')\n",
        "    bert_model = TFRobertaModel.from_pretrained('/content/pretrained-roberta-base.h5',config=config)\n",
        "    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n",
        "    \n",
        "    # Setting up layers\n",
        "    x1 = tf.keras.layers.Dropout(0.1)(x[0])\n",
        "    x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n",
        "    x1 = tf.keras.layers.ReLU()(x1)\n",
        "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
        "    x1 = tf.keras.layers.Dense(1)(x1)\n",
        "    x1 = tf.keras.layers.Flatten()(x1)\n",
        "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "\n",
        "    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n",
        "    x2 = tf.keras.layers.ReLU()(x2)\n",
        "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
        "    x2 = tf.keras.layers.Dense(1)(x2)\n",
        "    x2 = tf.keras.layers.Flatten()(x2)\n",
        "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
        "\n",
        "    # Initializing input,output for model.THis will be trained in next code\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
        "    #Adam optimizer for stochastic gradient descent.\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
        "    \n",
        "    # this is required as `model.predict` needs a fixed size!\n",
        "    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
        "    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
        "    \n",
        "    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
        "    return model, padded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3xaDY_hFbOr"
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    if (len(a)==0) & (len(b)==0): return 0.5\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVyeyQRCFeGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "524f9f0f-d6cd-42f5-b531-7885b7be6551"
      },
      "source": [
        "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
        "oof_start = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "oof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "preds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "preds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "\n",
        "#We train with 5 Stratified KFolds (based on sentiment stratification). \n",
        "#Each fold, the best model weights are saved and then reloaded before oof prediction and test prediction.\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=SEED)\n",
        "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print('### FOLD %i'%(fold+1))\n",
        "    print('#'*25)\n",
        "    \n",
        "    K.clear_session()\n",
        "    model, padded_model = build_model()\n",
        "        \n",
        "    #sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "    #    '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n",
        "    #    save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "    inpT = [input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]]\n",
        "    targetT = [start_tokens[idxT,], end_tokens[idxT,]]\n",
        "    inpV = [input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]]\n",
        "    targetV = [start_tokens[idxV,], end_tokens[idxV,]]\n",
        "    # sort the validation data\n",
        "    shuffleV = np.int32(sorted(range(len(inpV[0])), key=lambda k: (inpV[0][k] == PAD_ID).sum(), reverse=True))\n",
        "    inpV = [arr[shuffleV] for arr in inpV]\n",
        "    targetV = [arr[shuffleV] for arr in targetV]\n",
        "\n",
        "    weight_fn = '%s-roberta-%i.h5'%(VER,fold)\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        # sort and shuffle: We add random numbers to not have the same order in each epoch\n",
        "        shuffleT = np.int32(sorted(range(len(inpT[0])), key=lambda k: (inpT[0][k] == PAD_ID).sum() + np.random.randint(-3, 3), reverse=True))\n",
        "        # shuffle in batches, otherwise short batches will always come in the beginning of each epoch\n",
        "        num_batches = math.ceil(len(shuffleT) / BATCH_SIZE)\n",
        "        batch_inds = np.random.permutation(num_batches)\n",
        "        shuffleT_ = []\n",
        "        for batch_ind in batch_inds:\n",
        "            shuffleT_.append(shuffleT[batch_ind * BATCH_SIZE: (batch_ind + 1) * BATCH_SIZE])\n",
        "        shuffleT = np.concatenate(shuffleT_)\n",
        "        # reorder the input data\n",
        "        inpT = [arr[shuffleT] for arr in inpT]\n",
        "        targetT = [arr[shuffleT] for arr in targetT]\n",
        "        model.fit(inpT, targetT, \n",
        "            epochs=epoch, initial_epoch=epoch - 1, batch_size=BATCH_SIZE, verbose=DISPLAY, callbacks=[],\n",
        "            validation_data=(inpV, targetV), shuffle=False)  # don't shuffle in `fit`\n",
        "        save_weights(model, weight_fn)\n",
        "\n",
        "    print('Loading model...')\n",
        "    # model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n",
        "    load_weights(model, weight_fn)\n",
        "\n",
        "    print('Predicting OOF...')\n",
        "    oof_start[idxV,],oof_end[idxV,] = padded_model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n",
        "\n",
        "    print('Predicting Test...')\n",
        "    preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
        "    preds_start += preds[0]/skf.n_splits\n",
        "    preds_end += preds[1]/skf.n_splits\n",
        "    \n",
        "    # DISPLAY FOLD JACCARD\n",
        "    all = []\n",
        "    for k in idxV:\n",
        "        a = np.argmax(oof_start[k,])\n",
        "        b = np.argmax(oof_end[k,])\n",
        "        if a>b: \n",
        "            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n",
        "        else:\n",
        "            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
        "            enc = tokenizer.encode(text1)\n",
        "            st = tokenizer.decode(enc.ids[a-2:b-1])\n",
        "        all.append(jaccard(st,train.loc[k,'selected_text']))\n",
        "    jac.append(np.mean(all))\n",
        "    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#########################\n",
            "### FOLD 1\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFRobertaModel.\n",
            "\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at /content/pretrained-roberta-base.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "687/687 [==============================] - 292s 425ms/step - loss: 2.8991 - activation_loss: 1.4639 - activation_1_loss: 1.4353 - val_loss: 2.5610 - val_activation_loss: 1.2903 - val_activation_1_loss: 1.2707\n",
            "Epoch 2/2\n",
            "687/687 [==============================] - 277s 403ms/step - loss: 2.5499 - activation_loss: 1.2903 - activation_1_loss: 1.2596 - val_loss: 2.5203 - val_activation_loss: 1.2842 - val_activation_1_loss: 1.2361\n",
            "Epoch 3/3\n",
            "687/687 [==============================] - 276s 402ms/step - loss: 2.4308 - activation_loss: 1.2331 - activation_1_loss: 1.1977 - val_loss: 2.5345 - val_activation_loss: 1.2880 - val_activation_1_loss: 1.2465\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 33s 189ms/step\n",
            "Predicting Test...\n",
            "125/125 [==============================] - 24s 193ms/step\n",
            ">>>> FOLD 1 Jaccard = 0.7112143803715687\n",
            "\n",
            "#########################\n",
            "### FOLD 2\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFRobertaModel.\n",
            "\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at /content/pretrained-roberta-base.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "688/688 [==============================] - 284s 413ms/step - loss: 2.9528 - activation_loss: 1.4734 - activation_1_loss: 1.4795 - val_loss: 2.5524 - val_activation_loss: 1.2996 - val_activation_1_loss: 1.2528\n",
            "Epoch 2/2\n",
            "688/688 [==============================] - 280s 407ms/step - loss: 2.5731 - activation_loss: 1.3022 - activation_1_loss: 1.2710 - val_loss: 2.4808 - val_activation_loss: 1.2754 - val_activation_1_loss: 1.2054\n",
            "Epoch 3/3\n",
            "688/688 [==============================] - 297s 431ms/step - loss: 2.4961 - activation_loss: 1.2660 - activation_1_loss: 1.2301 - val_loss: 2.4978 - val_activation_loss: 1.2697 - val_activation_1_loss: 1.2280\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 32s 186ms/step\n",
            "Predicting Test...\n",
            "125/125 [==============================] - 24s 192ms/step\n",
            ">>>> FOLD 2 Jaccard = 0.7142707009894229\n",
            "\n",
            "#########################\n",
            "### FOLD 3\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFRobertaModel.\n",
            "\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at /content/pretrained-roberta-base.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "688/688 [==============================] - 287s 418ms/step - loss: 2.9362 - activation_loss: 1.4832 - activation_1_loss: 1.4530 - val_loss: 2.6408 - val_activation_loss: 1.3417 - val_activation_1_loss: 1.2991\n",
            "Epoch 2/2\n",
            "688/688 [==============================] - 278s 404ms/step - loss: 2.5489 - activation_loss: 1.2929 - activation_1_loss: 1.2560 - val_loss: 2.5424 - val_activation_loss: 1.2791 - val_activation_1_loss: 1.2633\n",
            "Epoch 3/3\n",
            "688/688 [==============================] - 285s 414ms/step - loss: 2.4567 - activation_loss: 1.2471 - activation_1_loss: 1.2096 - val_loss: 2.5367 - val_activation_loss: 1.2666 - val_activation_1_loss: 1.2700\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 32s 186ms/step\n",
            "Predicting Test...\n",
            "125/125 [==============================] - 25s 196ms/step\n",
            ">>>> FOLD 3 Jaccard = 0.7004193105889922\n",
            "\n",
            "#########################\n",
            "### FOLD 4\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFRobertaModel.\n",
            "\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at /content/pretrained-roberta-base.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "688/688 [==============================] - 286s 415ms/step - loss: 2.9028 - activation_loss: 1.4570 - activation_1_loss: 1.4458 - val_loss: 2.5661 - val_activation_loss: 1.3171 - val_activation_1_loss: 1.2490\n",
            "Epoch 2/2\n",
            "688/688 [==============================] - 279s 405ms/step - loss: 2.5334 - activation_loss: 1.2832 - activation_1_loss: 1.2502 - val_loss: 2.5657 - val_activation_loss: 1.3075 - val_activation_1_loss: 1.2582\n",
            "Epoch 3/3\n",
            "688/688 [==============================] - 305s 443ms/step - loss: 2.4700 - activation_loss: 1.2542 - activation_1_loss: 1.2158 - val_loss: 2.5474 - val_activation_loss: 1.2977 - val_activation_1_loss: 1.2497\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 32s 187ms/step\n",
            "Predicting Test...\n",
            "125/125 [==============================] - 24s 191ms/step\n",
            ">>>> FOLD 4 Jaccard = 0.6974498415870771\n",
            "\n",
            "#########################\n",
            "### FOLD 5\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFRobertaModel.\n",
            "\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at /content/pretrained-roberta-base.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "688/688 [==============================] - 309s 449ms/step - loss: 2.9559 - activation_loss: 1.4885 - activation_1_loss: 1.4674 - val_loss: 2.5265 - val_activation_loss: 1.2828 - val_activation_1_loss: 1.2438\n",
            "Epoch 2/2\n",
            "688/688 [==============================] - 286s 415ms/step - loss: 2.5564 - activation_loss: 1.2967 - activation_1_loss: 1.2597 - val_loss: 2.5165 - val_activation_loss: 1.2831 - val_activation_1_loss: 1.2334\n",
            "Epoch 3/3\n",
            "688/688 [==============================] - 295s 428ms/step - loss: 2.4581 - activation_loss: 1.2476 - activation_1_loss: 1.2105 - val_loss: 2.5175 - val_activation_loss: 1.2800 - val_activation_1_loss: 1.2375\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 32s 185ms/step\n",
            "Predicting Test...\n",
            "125/125 [==============================] - 24s 193ms/step\n",
            ">>>> FOLD 5 Jaccard = 0.700074324400614\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpLiPHFuFhjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b585f81-c2a0-43fe-eb50-a607a54a04c4"
      },
      "source": [
        "print('OVERALL 5Fold CV Jaccard =',np.mean(jac))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OVERALL 5Fold CV Jaccard = 0.7046857115875349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXwSlXVGiE1"
      },
      "source": [
        "all = []\n",
        "for k in range(input_ids_t.shape[0]):\n",
        "    a = np.argmax(preds_start[k,])\n",
        "    b = np.argmax(preds_end[k,])\n",
        "    if a>b: \n",
        "        st = test.loc[k,'Tweet']\n",
        "    else:\n",
        "        text1 = \" \"+\" \".join(test.loc[k,'Tweet'].split())\n",
        "        enc = tokenizer.encode(text1)\n",
        "        st = tokenizer.decode(enc.ids[a-2:b-1])\n",
        "    all.append(st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J0UcdykGiXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "97d7ea1c-4a90-4ff1-e745-ac7cefe9dc39"
      },
      "source": [
        "test['selected_text'] = all\n",
        "test[['Tweet','Sentiment','selected_text']].to_csv('/content/drive/My Drive/APIResultfinal.csv',index=False)\n",
        "pd.set_option('max_colwidth', 60)\n",
        "test.sample(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1428</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage waste use re...</td>\n",
              "      <td>negative</td>\n",
              "      <td>urstrulymahesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2941</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage waste use re...</td>\n",
              "      <td>negative</td>\n",
              "      <td>urstrulymahesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>RT ANKITA22239831 To attain natures blessings lets nurtu...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt ankita22239831 to attain natures blessings lets nurt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>RT androbliz The US President Trump Son Was Temporarily ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>false news about the pandemic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1921</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage waste use re...</td>\n",
              "      <td>negative</td>\n",
              "      <td>urstrulymahesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>RT EUENV 13 of Bulgaria is covered in forests The Natura...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt euenv 13 of bulgaria is covered in forests the natur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1774</th>\n",
              "      <td>RT AngloAmericanZA Our Mogalakwenas incubator support pr...</td>\n",
              "      <td>positive</td>\n",
              "      <td>support programme on groenfontein farm near our platinu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>RT urstrulyMahesh Save water recycle manage waste use re...</td>\n",
              "      <td>negative</td>\n",
              "      <td>urstrulymahesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>RT sachinrt My kitchen garden We can all take small step...</td>\n",
              "      <td>negative</td>\n",
              "      <td>sustainabilityworldnatureconservationday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>RT digitalkunwar</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt digitalkunwar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3674</th>\n",
              "      <td>RT IYCWestBengal In recent years we have seen our countr...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt iycwestbengal in recent years we have seen our count...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1695</th>\n",
              "      <td>RT SadhguruJV Right now the most important aspect of con...</td>\n",
              "      <td>positive</td>\n",
              "      <td>important</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>RT WWFDG We finally recognize the material value of biod...</td>\n",
              "      <td>positive</td>\n",
              "      <td>amazing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2508</th>\n",
              "      <td>RT IshaAfrica Right now the most important aspect of con...</td>\n",
              "      <td>positive</td>\n",
              "      <td>important</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2744</th>\n",
              "      <td>RT TravelCuddly New blog on Travel Cuddly Website WorldN...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wentworth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>RT SatlokChannel World Nature Conservation Day 2020 This...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt satlokchannel world nature conservation day 2020 thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>RT ishafoundation Right now the most important aspect of...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ishafoundation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>RT JAGANTRS WorldNatureConservationDay Lets fulfill our ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt jagantrs worldnatureconservationday lets fulfill our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3051</th>\n",
              "      <td>RT sudeshinsan10 Plantation campaign started by Saint Dr...</td>\n",
              "      <td>positive</td>\n",
              "      <td>more than 45 million tree have been planted so far saint d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1283</th>\n",
              "      <td>RT meenabishnoi</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt meenabishnoi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            Tweet  ...                                                selected_text\n",
              "1428  RT urstrulyMahesh Save water recycle manage waste use re...  ...                                               urstrulymahesh\n",
              "2941  RT urstrulyMahesh Save water recycle manage waste use re...  ...                                               urstrulymahesh\n",
              "2017  RT ANKITA22239831 To attain natures blessings lets nurtu...  ...   rt ankita22239831 to attain natures blessings lets nurt...\n",
              "1286  RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "1517  RT androbliz The US President Trump Son Was Temporarily ...  ...                                false news about the pandemic\n",
              "1921  RT urstrulyMahesh Save water recycle manage waste use re...  ...                                               urstrulymahesh\n",
              "560   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "1754  RT EUENV 13 of Bulgaria is covered in forests The Natura...  ...   rt euenv 13 of bulgaria is covered in forests the natur...\n",
              "327   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "1774  RT AngloAmericanZA Our Mogalakwenas incubator support pr...  ...   support programme on groenfontein farm near our platinu...\n",
              "1033  RT urstrulyMahesh Save water recycle manage waste use re...  ...                                               urstrulymahesh\n",
              "3260  RT sachinrt My kitchen garden We can all take small step...  ...                     sustainabilityworldnatureconservationday\n",
              "879                                              RT digitalkunwar  ...                                             rt digitalkunwar\n",
              "3674  RT IYCWestBengal In recent years we have seen our countr...  ...   rt iycwestbengal in recent years we have seen our count...\n",
              "1695  RT SadhguruJV Right now the most important aspect of con...  ...                                                    important\n",
              "1056  RT WWFDG We finally recognize the material value of biod...  ...                                                      amazing\n",
              "2508  RT IshaAfrica Right now the most important aspect of con...  ...                                                    important\n",
              "2744  RT TravelCuddly New blog on Travel Cuddly Website WorldN...  ...                                                    wentworth\n",
              "1614  RT SatlokChannel World Nature Conservation Day 2020 This...  ...   rt satlokchannel world nature conservation day 2020 thi...\n",
              "1519  RT ishafoundation Right now the most important aspect of...  ...                                               ishafoundation\n",
              "502   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "287   RT JAGANTRS WorldNatureConservationDay Lets fulfill our ...  ...   rt jagantrs worldnatureconservationday lets fulfill our...\n",
              "437   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "3051  RT sudeshinsan10 Plantation campaign started by Saint Dr...  ...   more than 45 million tree have been planted so far saint d\n",
              "1283                                              RT meenabishnoi  ...                                              rt meenabishnoi\n",
              "\n",
              "[25 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9w5jYRiX-kI"
      },
      "source": [
        "import pandas as pd\n",
        "Result = pd.read_csv('/content/drive/My Drive/APIResultfinal.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybacqxDoYDct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "e3c180c1-14c5-4ab7-b9cc-c52a1e6b4865"
      },
      "source": [
        "Result[Result['Sentiment']=='neutral'].sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>RT hakubhajamnagar</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt hakubhajamnagar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3835</th>\n",
              "      <td>RT ImRDSharmaInsan WorldNatureConservationDayderasachasa...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt imrdsharmainsan worldnatureconservationdayderasachas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>RT Abhishek5jntrm1 World Nature Conservation Day 2020 Th...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt abhishek5jntrm1 world nature conservation day 2020 t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>RT Daljeet53 WorldNatureConservationDay</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt daljeet53 worldnatureconservationday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>RT ManCity The year is 2045 Phil Foden is our manager an...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancity the year is 2045 phil foden is our manager a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1277</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>RT ManCityPT O ano 2045 Phil Foden o treinador do City q...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt mancitypt o ano 2045 phil foden o treinador do city ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3891</th>\n",
              "      <td>RT SatlokChannel World Nature Conservation Day 2020 This...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rt satlokchannel world nature conservation day 2020 thi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            Tweet  ...                                                selected_text\n",
              "3119                                           RT hakubhajamnagar  ...                                           rt hakubhajamnagar\n",
              "3835  RT ImRDSharmaInsan WorldNatureConservationDayderasachasa...  ...   rt imrdsharmainsan worldnatureconservationdayderasachas...\n",
              "1027  RT Abhishek5jntrm1 World Nature Conservation Day 2020 Th...  ...   rt abhishek5jntrm1 world nature conservation day 2020 t...\n",
              "247                       RT Daljeet53 WorldNatureConservationDay  ...                      rt daljeet53 worldnatureconservationday\n",
              "1459  RT ManCity The year is 2045 Phil Foden is our manager an...  ...   rt mancity the year is 2045 phil foden is our manager a...\n",
              "517   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "1277  RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "415   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "613   RT ManCityPT O ano 2045 Phil Foden o treinador do City q...  ...   rt mancitypt o ano 2045 phil foden o treinador do city ...\n",
              "3891  RT SatlokChannel World Nature Conservation Day 2020 This...  ...   rt satlokchannel world nature conservation day 2020 thi...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKO2F3ZeZzAd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
